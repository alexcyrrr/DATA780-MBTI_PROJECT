{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89a3a272-9115-4e7e-88cb-14eb3b38cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b104884-cce2-4716-ae37-daffd2124de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "df_reddit = pd.read_csv(\"/Users/lukestephens/Downloads/reddit_data.csv\", engine='python', on_bad_lines='skip')\n",
    "df_kaggle = pd.read_csv(\"/Users/lukestephens/Downloads/kaggle_data.csv\", engine='python', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb2a3f5-c868-4a1b-9a84-5038e298cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe for analysis\n",
    "df_results = pd.DataFrame(columns=[\n",
    "    'model', \n",
    "    'vectorizer', \n",
    "    'dataset', \n",
    "    'accuracy', \n",
    "    'precision', \n",
    "    'recall', \n",
    "    'f1_score'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dd7a3",
   "metadata": {},
   "source": [
    "First, we will examine model performance using both TF-IDF and CountVec vectorizers, in conjunction with Logistic Regression and Naive Bayes models. These tests will be performed both within datasets and across datasets for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7468a-3eab-495d-8623-35b79070ac66",
   "metadata": {},
   "source": [
    "# LR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef326a2-cac6-4432-88be-9659386f6cbb",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf43ac8e-e519-40ec-bd91-6886d4f5301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.31921143480104175\n",
      "Reddit Precision: 0.3161585494559101\n",
      "Reddit Recall: 0.31921143480104175\n",
      "Reddit F1-Score: 0.27030098958675136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.02      0.03      4146\n",
      "           1       0.28      0.04      0.07     19707\n",
      "           2       0.34      0.01      0.02      8606\n",
      "           3       0.30      0.13      0.18     38709\n",
      "           4       0.00      0.00      0.00       515\n",
      "           5       0.14      0.00      0.00      1530\n",
      "           6       0.29      0.01      0.01       866\n",
      "           7       0.45      0.01      0.02      2567\n",
      "           8       0.29      0.20      0.24     38870\n",
      "           9       0.28      0.15      0.20     35492\n",
      "          10       0.31      0.34      0.33     71610\n",
      "          11       0.33      0.68      0.44     90657\n",
      "          12       0.29      0.00      0.00      1369\n",
      "          13       0.51      0.02      0.05      2252\n",
      "          14       0.53      0.01      0.01      3300\n",
      "          15       0.38      0.01      0.02     10024\n",
      "\n",
      "    accuracy                           0.32    330220\n",
      "   macro avg       0.32      0.10      0.10    330220\n",
      "weighted avg       0.32      0.32      0.27    330220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "df_results.loc[0] = ['LogisticRegression', 'TF-IDF', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1aa5b2-b6f6-4734-b19c-7d68cf062ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Accuracy: 0.23812710657921954\n",
      "Kaggle Precision: 0.24464319590837802\n",
      "Kaggle Recall: 0.23812710657921954\n",
      "Kaggle F1-Score: 0.19192041644931035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.00      0.00      1831\n",
      "           1       0.21      0.04      0.07      6380\n",
      "           2       0.40      0.01      0.01      2192\n",
      "           3       0.19      0.05      0.08      6585\n",
      "           4       0.00      0.00      0.00       398\n",
      "           5       0.50      0.00      0.00       442\n",
      "           6       0.57      0.01      0.02       379\n",
      "           7       1.00      0.00      0.00       874\n",
      "           8       0.23      0.29      0.25     13902\n",
      "           9       0.26      0.57      0.35     17383\n",
      "          10       0.21      0.16      0.18     10380\n",
      "          11       0.23      0.27      0.25     12339\n",
      "          12       0.11      0.00      0.00      1546\n",
      "          13       0.34      0.01      0.02      2472\n",
      "          14       0.40      0.01      0.02      1963\n",
      "          15       0.20      0.01      0.02      3117\n",
      "\n",
      "    accuracy                           0.24     82183\n",
      "   macro avg       0.31      0.09      0.08     82183\n",
      "weighted avg       0.24      0.24      0.19     82183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['type']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Kaggle Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Kaggle Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Kaggle Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Kaggle F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "df_results.loc[1] = ['LogisticRegression', 'TF-IDF', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2e274d-e735-4bec-b9d3-73a7bcc27475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.18167504228368397\n",
      "Reddit Precision: 0.19207675574327213\n",
      "Reddit Recall: 0.18167504228368397\n",
      "Reddit F1-Score: 0.13783694631461985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.00      0.00      9104\n",
      "           1       0.18      0.02      0.04     32083\n",
      "           2       0.09      0.00      0.00     10988\n",
      "           3       0.13      0.07      0.09     33024\n",
      "           4       0.00      0.00      0.00      1986\n",
      "           5       0.00      0.00      0.00      2141\n",
      "           6       0.00      0.00      0.00      1880\n",
      "           7       0.03      0.00      0.00      4238\n",
      "           8       0.25      0.11      0.15     69990\n",
      "           9       0.32      0.12      0.17     86959\n",
      "          10       0.15      0.26      0.19     51129\n",
      "          11       0.17      0.65      0.27     61438\n",
      "          12       0.00      0.00      0.00      7886\n",
      "          13       0.02      0.00      0.00     12460\n",
      "          14       0.07      0.00      0.00      9628\n",
      "          15       0.21      0.00      0.01     15981\n",
      "\n",
      "    accuracy                           0.18    410915\n",
      "   macro avg       0.10      0.08      0.06    410915\n",
      "weighted avg       0.19      0.18      0.14    410915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train on Reddit, test on Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['class']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['type']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test_encoded, y_pred_lr))\n",
    "\n",
    "df_results.loc[2] = ['LogisticRegression', 'TF-IDF', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e74971-dda1-44f1-b306-dc2eb10f08e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.2092399006722791\n",
      "Reddit Precision: 0.23223226863217858\n",
      "Reddit Recall: 0.2092399006722791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit F1-Score: 0.1879682397877797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.00      0.00     20936\n",
      "           1       0.13      0.03      0.05     97835\n",
      "           2       0.10      0.00      0.00     43642\n",
      "           3       0.21      0.05      0.08    194338\n",
      "           4       0.00      0.00      0.00      2651\n",
      "           5       0.00      0.00      0.00      7483\n",
      "           6       0.00      0.00      0.00      4477\n",
      "           7       0.00      0.00      0.00     12793\n",
      "           8       0.17      0.30      0.22    194680\n",
      "           9       0.14      0.54      0.22    176991\n",
      "          10       0.29      0.14      0.18    358042\n",
      "          11       0.34      0.29      0.31    452235\n",
      "          12       0.06      0.00      0.01      7002\n",
      "          13       0.03      0.00      0.00     11345\n",
      "          14       0.02      0.00      0.00     16590\n",
      "          15       0.11      0.01      0.02     50060\n",
      "\n",
      "    accuracy                           0.21   1651100\n",
      "   macro avg       0.10      0.08      0.07   1651100\n",
      "weighted avg       0.23      0.21      0.19   1651100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train on Kaggle, test on Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['type']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test_encoded, y_pred_lr))\n",
    "\n",
    "df_results.loc[3] = ['LogisticRegression', 'TF-IDF', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688aa3c2-43f0-44b1-ad84-ca1d7bb20c65",
   "metadata": {},
   "source": [
    "### CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a9ab3e-3214-4a69-aec9-ed1e6c022981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.31497183695718006\n",
      "Reddit Precision: 0.3212123432636192\n",
      "Reddit Recall: 0.31497183695718006\n",
      "Reddit F1-Score: 0.24238728284882308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.01      0.03      4146\n",
      "           1       0.30      0.03      0.05     19707\n",
      "           2       0.24      0.01      0.01      8606\n",
      "           3       0.33      0.09      0.15     38709\n",
      "           4       0.00      0.00      0.00       515\n",
      "           5       0.08      0.00      0.00      1530\n",
      "           6       0.25      0.01      0.02       866\n",
      "           7       0.42      0.01      0.02      2567\n",
      "           8       0.34      0.13      0.19     38870\n",
      "           9       0.31      0.09      0.14     35492\n",
      "          10       0.33      0.23      0.27     71610\n",
      "          11       0.31      0.82      0.45     90657\n",
      "          12       0.08      0.00      0.00      1369\n",
      "          13       0.32      0.01      0.01      2252\n",
      "          14       0.45      0.01      0.02      3300\n",
      "          15       0.39      0.01      0.02     10024\n",
      "\n",
      "    accuracy                           0.31    330220\n",
      "   macro avg       0.29      0.09      0.09    330220\n",
      "weighted avg       0.32      0.31      0.24    330220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Reddit\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "df_results.loc[4] = ['LogisticRegression', 'CountVec', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15e6e21-774c-457d-b53e-37a859c091d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Accuracy: 0.22932966671939453\n",
      "Kaggle Precision: 0.2029003045259884\n",
      "Kaggle Recall: 0.22932966671939453\n",
      "Kaggle F1-Score: 0.1949479073086308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.01      0.02      1831\n",
      "           1       0.18      0.08      0.11      6380\n",
      "           2       0.11      0.02      0.03      2192\n",
      "           3       0.17      0.07      0.10      6585\n",
      "           4       0.07      0.01      0.01       398\n",
      "           5       0.20      0.01      0.02       442\n",
      "           6       0.22      0.02      0.04       379\n",
      "           7       0.06      0.00      0.01       874\n",
      "           8       0.23      0.26      0.25     13902\n",
      "           9       0.25      0.53      0.34     17383\n",
      "          10       0.21      0.16      0.18     10380\n",
      "          11       0.22      0.25      0.23     12339\n",
      "          12       0.13      0.02      0.03      1546\n",
      "          13       0.13      0.02      0.03      2472\n",
      "          14       0.17      0.03      0.05      1963\n",
      "          15       0.13      0.03      0.05      3117\n",
      "\n",
      "    accuracy                           0.23     82183\n",
      "   macro avg       0.16      0.10      0.09     82183\n",
      "weighted avg       0.20      0.23      0.19     82183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Kaggle\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['type']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Kaggle Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Kaggle Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Kaggle Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Kaggle F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "df_results.loc[5] = ['LogisticRegression', 'CountVec', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7984d5-5884-48bc-8b0b-3329b81a9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.16018641324848204\n",
      "Reddit Precision: 0.21786613439555413\n",
      "Reddit Recall: 0.16018641324848204\n",
      "Reddit F1-Score: 0.07957339969964851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      9104\n",
      "           1       0.25      0.00      0.00     32083\n",
      "           2       0.00      0.00      0.00     10988\n",
      "           3       0.11      0.02      0.04     33024\n",
      "           4       0.00      0.00      0.00      1986\n",
      "           5       0.00      0.00      0.00      2141\n",
      "           6       0.00      0.00      0.00      1880\n",
      "           7       0.00      0.00      0.00      4238\n",
      "           8       0.26      0.03      0.06     69990\n",
      "           9       0.34      0.03      0.05     86959\n",
      "          10       0.15      0.12      0.13     51129\n",
      "          11       0.16      0.88      0.27     61438\n",
      "          12       1.00      0.00      0.00      7886\n",
      "          13       0.43      0.00      0.00     12460\n",
      "          14       0.00      0.00      0.00      9628\n",
      "          15       0.00      0.00      0.00     15981\n",
      "\n",
      "    accuracy                           0.16    410915\n",
      "   macro avg       0.17      0.07      0.03    410915\n",
      "weighted avg       0.22      0.16      0.08    410915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train on Reddit, test on Kaggle\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['class']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['type']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test_encoded, y_pred_lr))\n",
    "\n",
    "df_results.loc[6] = ['LogisticRegression', 'CountVec', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd17bde-6646-488a-966d-89847f9d877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.19724668402882928\n",
      "Reddit Precision: 0.22562518996060346\n",
      "Reddit Recall: 0.19724668402882928\n",
      "Reddit F1-Score: 0.18629241920231834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.01      0.02     20936\n",
      "           1       0.12      0.06      0.07     97835\n",
      "           2       0.06      0.02      0.03     43642\n",
      "           3       0.19      0.06      0.09    194338\n",
      "           4       0.01      0.01      0.01      2651\n",
      "           5       0.00      0.00      0.00      7483\n",
      "           6       0.00      0.00      0.00      4477\n",
      "           7       0.02      0.00      0.01     12793\n",
      "           8       0.17      0.27      0.21    194680\n",
      "           9       0.13      0.50      0.21    176991\n",
      "          10       0.29      0.14      0.19    358042\n",
      "          11       0.34      0.25      0.29    452235\n",
      "          12       0.02      0.01      0.02      7002\n",
      "          13       0.02      0.01      0.02     11345\n",
      "          14       0.02      0.01      0.01     16590\n",
      "          15       0.07      0.03      0.04     50060\n",
      "\n",
      "    accuracy                           0.20   1651100\n",
      "   macro avg       0.09      0.09      0.08   1651100\n",
      "weighted avg       0.23      0.20      0.19   1651100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on Kaggle, test on Reddit\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['type']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test_encoded, y_pred_lr))\n",
    "\n",
    "df_results.loc[7] = ['LogisticRegression', 'CountVec', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad2791-9940-48ca-b5da-cd19c42ea2b1",
   "metadata": {},
   "source": [
    "# NB Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccdaed9-402d-4b28-8226-eac1de389e62",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf8786e-6ea9-486c-9dd8-a7e73b793f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.305784022772697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Precision: 0.32478778734350283\n",
      "Reddit Recall: 0.305784022772697\n",
      "Reddit F1-Score: 0.21558668068831335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.53      0.00      0.00      4146\n",
      "        ENFP       0.39      0.00      0.01     19707\n",
      "        ENTJ       0.36      0.00      0.00      8606\n",
      "        ENTP       0.33      0.04      0.08     38709\n",
      "        ESFJ       0.00      0.00      0.00       515\n",
      "        ESFP       0.10      0.00      0.00      1530\n",
      "        ESTJ       0.00      0.00      0.00       866\n",
      "        ESTP       0.00      0.00      0.00      2567\n",
      "        INFJ       0.34      0.09      0.14     38870\n",
      "        INFP       0.34      0.06      0.11     35492\n",
      "        INTJ       0.32      0.21      0.25     71610\n",
      "        INTP       0.30      0.86      0.45     90657\n",
      "        ISFJ       0.00      0.00      0.00      1369\n",
      "        ISFP       0.00      0.00      0.00      2252\n",
      "        ISTJ       0.25      0.00      0.00      3300\n",
      "        ISTP       0.49      0.00      0.00     10024\n",
      "\n",
      "    accuracy                           0.31    330220\n",
      "   macro avg       0.23      0.08      0.07    330220\n",
      "weighted avg       0.32      0.31      0.22    330220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[8] = ['NB', 'TF-IDF', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800d3a91-1809-44b6-b83c-efcff57f117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Accuracy: 0.23700765365099838\n",
      "Kaggle Precision: 0.23506736800666486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Recall: 0.23700765365099838\n",
      "Kaggle F1-Score: 0.16263106017249235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00      1821\n",
      "        ENFP       0.29      0.01      0.02      6416\n",
      "        ENTJ       0.17      0.00      0.00      2198\n",
      "        ENTP       0.23      0.01      0.02      6605\n",
      "        ESFJ       0.00      0.00      0.00       397\n",
      "        ESFP       0.00      0.00      0.00       428\n",
      "        ESTJ       0.00      0.00      0.00       376\n",
      "        ESTP       0.00      0.00      0.00       848\n",
      "        INFJ       0.23      0.20      0.21     13998\n",
      "        INFP       0.24      0.77      0.36     17392\n",
      "        INTJ       0.23      0.07      0.10     10226\n",
      "        INTP       0.25      0.20      0.22     12288\n",
      "        ISFJ       0.11      0.00      0.00      1577\n",
      "        ISFP       0.22      0.00      0.00      2492\n",
      "        ISTJ       0.50      0.00      0.00      1925\n",
      "        ISTP       0.35      0.00      0.01      3196\n",
      "\n",
      "    accuracy                           0.24     82183\n",
      "   macro avg       0.18      0.08      0.06     82183\n",
      "weighted avg       0.24      0.24      0.16     82183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Kaggle Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Kaggle Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Kaggle Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Kaggle F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[9] = ['NB', 'TF-IDF', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b9142bc-e6a1-41a9-8757-fcd4f14c39c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.1647859046274777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Precision: 0.20222540832838592\n",
      "Reddit Recall: 0.1647859046274777\n",
      "Reddit F1-Score: 0.09098147775787258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00      9104\n",
      "        ENFP       0.21      0.00      0.00     32083\n",
      "        ENTJ       0.12      0.00      0.00     10988\n",
      "        ENTP       0.14      0.02      0.04     33024\n",
      "        ESFJ       0.00      0.00      0.00      1986\n",
      "        ESFP       0.00      0.00      0.00      2141\n",
      "        ESTJ       0.00      0.00      0.00      1880\n",
      "        ESTP       0.00      0.00      0.00      4238\n",
      "        INFJ       0.27      0.04      0.07     69990\n",
      "        INFP       0.34      0.05      0.08     86959\n",
      "        INTJ       0.15      0.14      0.14     51129\n",
      "        INTP       0.16      0.86      0.27     61438\n",
      "        ISFJ       0.00      0.00      0.00      7886\n",
      "        ISFP       0.00      0.00      0.00     12460\n",
      "        ISTJ       0.00      0.00      0.00      9628\n",
      "        ISTP       0.29      0.00      0.00     15981\n",
      "\n",
      "    accuracy                           0.16    410915\n",
      "   macro avg       0.10      0.07      0.04    410915\n",
      "weighted avg       0.20      0.16      0.09    410915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train on Reddit, test on Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['class']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['type']\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[10] = ['NB', 'TF-IDF', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c3198c-89ab-46f5-9955-c07e3cf94314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.18282296650717703\n",
      "Reddit Precision: 0.23696265084964713\n",
      "Reddit Recall: 0.18282296650717703\n",
      "Reddit F1-Score: 0.14810504664239446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00     20936\n",
      "        ENFP       0.11      0.00      0.00     97835\n",
      "        ENTJ       0.09      0.00      0.00     43642\n",
      "        ENTP       0.24      0.01      0.02    194338\n",
      "        ESFJ       0.00      0.00      0.00      2651\n",
      "        ESFP       0.00      0.00      0.00      7483\n",
      "        ESTJ       0.00      0.00      0.00      4477\n",
      "        ESTP       0.00      0.00      0.00     12793\n",
      "        INFJ       0.17      0.20      0.18    194680\n",
      "        INFP       0.13      0.73      0.21    176991\n",
      "        INTJ       0.31      0.06      0.10    358042\n",
      "        INTP       0.35      0.24      0.29    452235\n",
      "        ISFJ       0.00      0.00      0.00      7002\n",
      "        ISFP       0.03      0.00      0.00     11345\n",
      "        ISTJ       0.01      0.00      0.00     16590\n",
      "        ISTP       0.13      0.00      0.00     50060\n",
      "\n",
      "    accuracy                           0.18   1651100\n",
      "   macro avg       0.10      0.08      0.05   1651100\n",
      "weighted avg       0.24      0.18      0.15   1651100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on Kaggle, test on Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['type']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['class']\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[11] = ['NB', 'TF-IDF', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385e50c-f763-4ab2-824e-1933698696a1",
   "metadata": {},
   "source": [
    "### CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f9a334-3ab6-4e27-aa1e-a3f085fe1188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.2863151838168494\n",
      "Reddit Precision: 0.271354271619472\n",
      "Reddit Recall: 0.2863151838168494\n",
      "Reddit F1-Score: 0.26771256595900367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.12      0.07      0.09      4146\n",
      "        ENFP       0.17      0.13      0.15     19707\n",
      "        ENTJ       0.13      0.06      0.08      8606\n",
      "        ENTP       0.26      0.16      0.20     38709\n",
      "        ESFJ       0.02      0.02      0.02       515\n",
      "        ESFP       0.05      0.03      0.04      1530\n",
      "        ESTJ       0.04      0.11      0.06       866\n",
      "        ESTP       0.06      0.09      0.07      2567\n",
      "        INFJ       0.23      0.26      0.25     38870\n",
      "        INFP       0.24      0.21      0.22     35492\n",
      "        INTJ       0.33      0.23      0.27     71610\n",
      "        INTP       0.35      0.55      0.42     90657\n",
      "        ISFJ       0.04      0.02      0.03      1369\n",
      "        ISFP       0.07      0.07      0.07      2252\n",
      "        ISTJ       0.08      0.05      0.06      3300\n",
      "        ISTP       0.14      0.05      0.07     10024\n",
      "\n",
      "    accuracy                           0.29    330220\n",
      "   macro avg       0.15      0.13      0.13    330220\n",
      "weighted avg       0.27      0.29      0.27    330220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Reddit\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[12] = ['NB', 'CountVec', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db992a6-254c-4458-8be5-5bb96182df51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Accuracy: 0.22918365112006134\n",
      "Kaggle Precision: 0.2008082517892558\n",
      "Kaggle Recall: 0.22918365112006134\n",
      "Kaggle F1-Score: 0.20163816502668266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.07      0.01      0.02      1831\n",
      "        ENFP       0.18      0.10      0.13      6380\n",
      "        ENTJ       0.10      0.03      0.05      2192\n",
      "        ENTP       0.17      0.08      0.11      6585\n",
      "        ESFJ       0.02      0.01      0.01       398\n",
      "        ESFP       0.02      0.01      0.01       442\n",
      "        ESTJ       0.04      0.02      0.02       379\n",
      "        ESTP       0.03      0.01      0.01       874\n",
      "        INFJ       0.23      0.26      0.25     13902\n",
      "        INFP       0.26      0.50      0.34     17383\n",
      "        INTJ       0.21      0.18      0.19     10380\n",
      "        INTP       0.24      0.24      0.24     12339\n",
      "        ISFJ       0.08      0.01      0.03      1546\n",
      "        ISFP       0.09      0.02      0.04      2472\n",
      "        ISTJ       0.12      0.04      0.06      1963\n",
      "        ISTP       0.12      0.06      0.08      3117\n",
      "\n",
      "    accuracy                           0.23     82183\n",
      "   macro avg       0.12      0.10      0.10     82183\n",
      "weighted avg       0.20      0.23      0.20     82183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train & test on Kaggle\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Kaggle Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Kaggle Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Kaggle Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Kaggle F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[13] = ['NB', 'CountVec', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c91742-9172-4605-a4cb-cb65308dc958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.19602107491817042\n",
      "Reddit Precision: 0.18478044726203807\n",
      "Reddit Recall: 0.19602107491817042\n",
      "Reddit F1-Score: 0.17349041767447462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.03      0.01      0.01      9104\n",
      "        ENFP       0.14      0.08      0.10     32083\n",
      "        ENTJ       0.09      0.01      0.02     10988\n",
      "        ENTP       0.13      0.10      0.11     33024\n",
      "        ESFJ       0.00      0.00      0.00      1986\n",
      "        ESFP       0.01      0.01      0.01      2141\n",
      "        ESTJ       0.00      0.00      0.00      1880\n",
      "        ESTP       0.02      0.01      0.01      4238\n",
      "        INFJ       0.23      0.20      0.22     69990\n",
      "        INFP       0.30      0.21      0.25     86959\n",
      "        INTJ       0.17      0.21      0.18     51129\n",
      "        INTP       0.19      0.50      0.27     61438\n",
      "        ISFJ       0.07      0.01      0.01      7886\n",
      "        ISFP       0.06      0.01      0.02     12460\n",
      "        ISTJ       0.05      0.01      0.01      9628\n",
      "        ISTP       0.13      0.02      0.04     15981\n",
      "\n",
      "    accuracy                           0.20    410915\n",
      "   macro avg       0.10      0.09      0.08    410915\n",
      "weighted avg       0.18      0.20      0.17    410915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on Reddit, test on Kaggle\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['class']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['type']\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[14] = ['NB', 'CountVec', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a82a310-db66-42bb-8f5c-fb5b47b6bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.2048361698261765\n",
      "Reddit Precision: 0.2306031875696996\n",
      "Reddit Recall: 0.2048361698261765\n",
      "Reddit F1-Score: 0.19788045322519768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.03      0.01      0.01     20936\n",
      "        ENFP       0.12      0.06      0.08     97835\n",
      "        ENTJ       0.06      0.04      0.04     43642\n",
      "        ENTP       0.20      0.08      0.12    194338\n",
      "        ESFJ       0.00      0.00      0.00      2651\n",
      "        ESFP       0.00      0.00      0.00      7483\n",
      "        ESTJ       0.00      0.00      0.00      4477\n",
      "        ESTP       0.01      0.00      0.01     12793\n",
      "        INFJ       0.19      0.25      0.21    194680\n",
      "        INFP       0.14      0.48      0.22    176991\n",
      "        INTJ       0.29      0.16      0.20    358042\n",
      "        INTP       0.35      0.27      0.30    452235\n",
      "        ISFJ       0.01      0.01      0.01      7002\n",
      "        ISFP       0.02      0.02      0.02     11345\n",
      "        ISTJ       0.02      0.01      0.02     16590\n",
      "        ISTP       0.06      0.05      0.06     50060\n",
      "\n",
      "    accuracy                           0.20   1651100\n",
      "   macro avg       0.09      0.09      0.08   1651100\n",
      "weighted avg       0.23      0.20      0.20   1651100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on Kaggle, test on Reddit\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['type']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['class']\n",
    "\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "df_results.loc[15] = ['NB', 'CountVec', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0000dcd4-ac49-46fb-8145-08a40704e680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.319211</td>\n",
       "      <td>0.316159</td>\n",
       "      <td>0.319211</td>\n",
       "      <td>0.270301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.238127</td>\n",
       "      <td>0.244643</td>\n",
       "      <td>0.238127</td>\n",
       "      <td>0.191920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.181675</td>\n",
       "      <td>0.192077</td>\n",
       "      <td>0.181675</td>\n",
       "      <td>0.137837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.209240</td>\n",
       "      <td>0.232232</td>\n",
       "      <td>0.209240</td>\n",
       "      <td>0.187968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.314972</td>\n",
       "      <td>0.321212</td>\n",
       "      <td>0.314972</td>\n",
       "      <td>0.242387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.229330</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.229330</td>\n",
       "      <td>0.194948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.160186</td>\n",
       "      <td>0.217866</td>\n",
       "      <td>0.160186</td>\n",
       "      <td>0.079573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.197247</td>\n",
       "      <td>0.225625</td>\n",
       "      <td>0.197247</td>\n",
       "      <td>0.186292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NB</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.305784</td>\n",
       "      <td>0.324788</td>\n",
       "      <td>0.305784</td>\n",
       "      <td>0.215587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NB</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.237008</td>\n",
       "      <td>0.235067</td>\n",
       "      <td>0.237008</td>\n",
       "      <td>0.162631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NB</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.164786</td>\n",
       "      <td>0.202225</td>\n",
       "      <td>0.164786</td>\n",
       "      <td>0.090981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NB</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.182823</td>\n",
       "      <td>0.236963</td>\n",
       "      <td>0.182823</td>\n",
       "      <td>0.148105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NB</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.286315</td>\n",
       "      <td>0.271354</td>\n",
       "      <td>0.286315</td>\n",
       "      <td>0.267713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NB</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.229184</td>\n",
       "      <td>0.200808</td>\n",
       "      <td>0.229184</td>\n",
       "      <td>0.201638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NB</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.196021</td>\n",
       "      <td>0.184780</td>\n",
       "      <td>0.196021</td>\n",
       "      <td>0.173490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NB</td>\n",
       "      <td>CountVec</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.230603</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.197880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model vectorizer                    dataset  accuracy  \\\n",
       "0   LogisticRegression     TF-IDF                     Reddit  0.319211   \n",
       "1   LogisticRegression     TF-IDF                     Kaggle  0.238127   \n",
       "2   LogisticRegression     TF-IDF  Train Reddit, Test Kaggle  0.181675   \n",
       "3   LogisticRegression     TF-IDF  Train Kaggle, Test Reddit  0.209240   \n",
       "4   LogisticRegression   CountVec                     Reddit  0.314972   \n",
       "5   LogisticRegression   CountVec                     Kaggle  0.229330   \n",
       "6   LogisticRegression   CountVec  Train Reddit, Test Kaggle  0.160186   \n",
       "7   LogisticRegression   CountVec  Train Kaggle, Test Reddit  0.197247   \n",
       "8                   NB     TF-IDF                     Reddit  0.305784   \n",
       "9                   NB     TF-IDF                     Kaggle  0.237008   \n",
       "10                  NB     TF-IDF  Train Reddit, Test Kaggle  0.164786   \n",
       "11                  NB     TF-IDF  Train Kaggle, Test Reddit  0.182823   \n",
       "12                  NB   CountVec                     Reddit  0.286315   \n",
       "13                  NB   CountVec                     Kaggle  0.229184   \n",
       "14                  NB   CountVec  Train Reddit, Test Kaggle  0.196021   \n",
       "15                  NB   CountVec  Train Kaggle, Test Reddit  0.204836   \n",
       "\n",
       "    precision    recall  f1_score  \n",
       "0    0.316159  0.319211  0.270301  \n",
       "1    0.244643  0.238127  0.191920  \n",
       "2    0.192077  0.181675  0.137837  \n",
       "3    0.232232  0.209240  0.187968  \n",
       "4    0.321212  0.314972  0.242387  \n",
       "5    0.202900  0.229330  0.194948  \n",
       "6    0.217866  0.160186  0.079573  \n",
       "7    0.225625  0.197247  0.186292  \n",
       "8    0.324788  0.305784  0.215587  \n",
       "9    0.235067  0.237008  0.162631  \n",
       "10   0.202225  0.164786  0.090981  \n",
       "11   0.236963  0.182823  0.148105  \n",
       "12   0.271354  0.286315  0.267713  \n",
       "13   0.200808  0.229184  0.201638  \n",
       "14   0.184780  0.196021  0.173490  \n",
       "15   0.230603  0.204836  0.197880  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab149b0",
   "metadata": {},
   "source": [
    "Above we see the results of these tests. Analysis (which will be discussed in the writeup) leads to the conclusion that a Logistic Regression model using the TF-IDF vectorizer results in the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a32ecc",
   "metadata": {},
   "source": [
    "### SVC Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96b4070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test accuracy: 0.3156\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "svc_basic = LinearSVC(\n",
    "    C=1.0,         \n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    dual=False       \n",
    ")\n",
    "\n",
    "svc_basic.fit(X_train, y_train)\n",
    "\n",
    "y_pred_basic = svc_basic.predict(X_test)\n",
    "accuracy_basic = accuracy_score(y_test, y_pred_basic)\n",
    "\n",
    "print(f\"   Test accuracy: {accuracy_basic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89629515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test accuracy: 0.3156\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "svc_balanced = LinearSVC(\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    loss='squared_hinge', \n",
    "    dual=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svc_basic.fit(X_train, y_train)\n",
    "\n",
    "y_pred_basic = svc_basic.predict(X_test)\n",
    "accuracy_basic = accuracy_score(y_test, y_pred_basic)\n",
    "\n",
    "print(f\"   Test accuracy: {accuracy_basic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b35377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test accuracy: 0.3153\n",
      "Reddit Precision: 0.32061663859426603\n",
      "Reddit Recall: 0.31525043910120526\n",
      "Reddit F1-Score: 0.2492733189916425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.02      0.03      4146\n",
      "           1       0.29      0.02      0.03     19707\n",
      "           2       0.41      0.01      0.01      8606\n",
      "           3       0.33      0.09      0.14     38709\n",
      "           4       0.00      0.00      0.00       515\n",
      "           5       0.22      0.00      0.00      1530\n",
      "           6       0.00      0.00      0.00       866\n",
      "           7       0.26      0.00      0.01      2567\n",
      "           8       0.32      0.14      0.20     38870\n",
      "           9       0.32      0.10      0.16     35492\n",
      "          10       0.31      0.31      0.31     71610\n",
      "          11       0.32      0.76      0.45     90657\n",
      "          12       0.00      0.00      0.00      1369\n",
      "          13       0.55      0.02      0.05      2252\n",
      "          14       0.40      0.00      0.00      3300\n",
      "          15       0.43      0.01      0.01     10024\n",
      "\n",
      "    accuracy                           0.32    330220\n",
      "   macro avg       0.28      0.09      0.09    330220\n",
      "weighted avg       0.32      0.32      0.25    330220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "svc_calibrated = CalibratedClassifierCV(\n",
    "    LinearSVC(C=1.0, max_iter=2000, dual=False, random_state=42),\n",
    "    cv=3,\n",
    "    method='sigmoid'\n",
    ")\n",
    "\n",
    "svc_calibrated.fit(X_train, y_train)\n",
    "\n",
    "y_pred_calib = svc_calibrated.predict(X_test)\n",
    "y_proba_calib = svc_calibrated.predict_proba(X_test)\n",
    "accuracy_calib = accuracy_score(y_test, y_pred_calib)\n",
    "\n",
    "print(f\"   Test accuracy: {accuracy_calib:.4f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_calib, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_calib, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test,y_pred_calib, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_calib))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8960ee5",
   "metadata": {},
   "source": [
    "### SMOTE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "383f887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1),\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efaea92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f24f8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test accuracy: 0.1346\n"
     ]
    }
   ],
   "source": [
    "svc_basic = LinearSVC(\n",
    "    C=1.0,             \n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    dual=False       \n",
    ")\n",
    "\n",
    "svc_basic.fit(X_train, y_train)\n",
    "\n",
    "y_pred_basic = svc_basic.predict(X_test)\n",
    "accuracy_basic = accuracy_score(y_test, y_pred_basic)\n",
    "\n",
    "print(f\"   Test accuracy: {accuracy_basic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with Reddit data\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['class']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408905e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7334c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.16080188964932468\n",
      "Reddit Precision: 0.2917230114265556\n",
      "Reddit Recall: 0.16080188964932468\n",
      "Reddit F1-Score: 0.19937225837230244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.19      0.07      4187\n",
      "           1       0.14      0.12      0.13     19567\n",
      "           2       0.08      0.13      0.10      8728\n",
      "           3       0.26      0.13      0.18     38868\n",
      "           4       0.01      0.18      0.01       530\n",
      "           5       0.01      0.19      0.02      1497\n",
      "           6       0.01      0.21      0.02       895\n",
      "           7       0.03      0.17      0.05      2559\n",
      "           8       0.28      0.17      0.21     38936\n",
      "           9       0.26      0.16      0.20     35398\n",
      "          10       0.36      0.18      0.24     71609\n",
      "          11       0.40      0.18      0.24     90447\n",
      "          12       0.01      0.14      0.02      1400\n",
      "          13       0.02      0.16      0.04      2269\n",
      "          14       0.03      0.14      0.05      3318\n",
      "          15       0.07      0.10      0.08     10012\n",
      "\n",
      "    accuracy                           0.16    330220\n",
      "   macro avg       0.13      0.16      0.10    330220\n",
      "weighted avg       0.29      0.16      0.20    330220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106f3f4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce3c60",
   "metadata": {},
   "source": [
    "Next, hyperparameters for the Logistic Regression model will be tested to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2acf00da-ca4e-42bb-9a51-857a6b8c0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................C=0.01, solver=newton-cg; total time=  54.5s\n",
      "[CV] END ...........................C=0.01, solver=newton-cg; total time=  54.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................C=0.01, solver=newton-cg; total time=  55.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................C=0.01, solver=lbfgs; total time= 1.1min\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.01, solver=saga; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.01, solver=saga; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................C=0.01, solver=lbfgs; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.01, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=0.1, solver=saga; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=0.1, solver=newton-cg; total time= 1.7min\n",
      "[CV] END ............................C=0.1, solver=newton-cg; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=0.1, solver=newton-cg; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=0.1, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=0.1, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.1, solver=lbfgs; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.1, solver=lbfgs; total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.1, solver=lbfgs; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=1.0, solver=saga; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=1.0, solver=saga; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=1.0, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=1.0, solver=newton-cg; total time= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=1.0, solver=newton-cg; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=1.0, solver=newton-cg; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=1.0, solver=lbfgs; total time= 9.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=1.0, solver=lbfgs; total time=10.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=1.0, solver=lbfgs; total time=10.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=10.0, solver=saga; total time= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=10.0, solver=saga; total time= 3.2min\n",
      "[CV] END ................................C=10.0, solver=saga; total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................C=10.0, solver=lbfgs; total time=15.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................C=10.0, solver=lbfgs; total time=14.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................C=10.0, solver=lbfgs; total time=13.1min\n",
      "[CV] END ...........................C=10.0, solver=newton-cg; total time=13.1min\n",
      "[CV] END ...........................C=10.0, solver=newton-cg; total time=11.7min\n",
      "[CV] END ...........................C=10.0, solver=newton-cg; total time=13.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestephens/.julia/conda/3/aarch64/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Logistic Regression Parameters:\n",
      "{'C': 1.0, 'solver': 'saga'}\n",
      "Best Cross-Validation Score: 0.3150\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'saga'] \n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    LogisticRegression(penalty = 'l2', multi_class='multinomial', max_iter=1000),\n",
    "    param_grid_lr,\n",
    "    cv=3,                     \n",
    "    scoring='accuracy',                 \n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Logistic Regression Parameters:\")\n",
    "print(grid_search_lr.best_params_)\n",
    "print(f\"Best Cross-Validation Score: {grid_search_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251068e3",
   "metadata": {},
   "source": [
    "It is determined that a C of 1.0 and the saga solver (along with l2 regularization) are optimal for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04313105",
   "metadata": {},
   "source": [
    "### Use the model on individual MBTI components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444be954",
   "metadata": {},
   "source": [
    "Next, the model will be trained and tested on the invidual MBTI components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cadfddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results df for analysis\n",
    "df_results_breakdown = pd.DataFrame(columns=[\n",
    "    'mbti component', \n",
    "    'dataset', \n",
    "    'accuracy', \n",
    "    'precision', \n",
    "    'recall', \n",
    "    'f1_score'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.599027920780086\n",
      "Reddit Precision: 0.6841687550329978\n",
      "Reddit Recall: 0.599027920780086\n",
      "Reddit F1-Score: 0.6273626599232306\n"
     ]
    }
   ],
   "source": [
    "# I/E - Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['Introvert']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[0] = ['I/E', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a27221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.677009266549573\n",
      "Reddit Precision: 0.8865199103644574\n",
      "Reddit Recall: 0.677009266549573\n",
      "Reddit F1-Score: 0.7564363853236461\n"
     ]
    }
   ],
   "source": [
    "# S/N - Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['Sensing']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[1] = ['S/N', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137ac7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.6138120041184665\n",
      "Reddit Precision: 0.6597719965851747\n",
      "Reddit Recall: 0.6138120041184665\n",
      "Reddit F1-Score: 0.6267227609866552\n"
     ]
    }
   ],
   "source": [
    "# T/F - Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['Thinking']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[2] = ['T/F', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4de08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5593452849615408\n",
      "Reddit Precision: 0.5774112516275652\n",
      "Reddit Recall: 0.5593452849615408\n",
      "Reddit F1-Score: 0.564316667715644\n"
     ]
    }
   ],
   "source": [
    "# J/P - Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y = df_reddit['Judging']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[3] = ['J/P', 'Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44840efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.6368470364917319\n",
      "Reddit Precision: 0.6604766674789874\n",
      "Reddit Recall: 0.6368470364917319\n",
      "Reddit F1-Score: 0.6475668067445254\n"
     ]
    }
   ],
   "source": [
    "# I/E - Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['Introvert']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[4] = ['I/E', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35d7b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.7075672584354429\n",
      "Reddit Precision: 0.7771824237799397\n",
      "Reddit Recall: 0.7075672584354429\n",
      "Reddit F1-Score: 0.7375172281660003\n"
     ]
    }
   ],
   "source": [
    "# S/N - Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['Sensing']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[5] = ['S/N', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49ac858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.601328741953932\n",
      "Reddit Precision: 0.6026284657936227\n",
      "Reddit Recall: 0.601328741953932\n",
      "Reddit F1-Score: 0.6017929442278941\n"
     ]
    }
   ],
   "source": [
    "# T/F - Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['Thinking']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[6] = ['T/F', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8b4f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5494810362240367\n",
      "Reddit Precision: 0.5514008383323892\n",
      "Reddit Recall: 0.5494810362240367\n",
      "Reddit F1-Score: 0.5503903692805392\n"
     ]
    }
   ],
   "source": [
    "# J/P - Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y = df_kaggle['Judging']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[7] = ['J/P', 'Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b33ea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5556745312290863\n",
      "Reddit Precision: 0.6672968489917573\n",
      "Reddit Recall: 0.5556745312290863\n",
      "Reddit F1-Score: 0.5896641872698957\n"
     ]
    }
   ],
   "source": [
    "# I/E - Train Reddit, Test Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['Introvert']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['Introvert']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[8] = ['I/E', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5699fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.6323302872856917\n",
      "Reddit Precision: 0.7779562836165688\n",
      "Reddit Recall: 0.6323302872856917\n",
      "Reddit F1-Score: 0.6862086782493854\n"
     ]
    }
   ],
   "source": [
    "# S/N - Train Reddit, Test Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['Sensing']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['Sensing']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[9] = ['S/N', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba4e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5900198337855761\n",
      "Reddit Precision: 0.5885752932939503\n",
      "Reddit Recall: 0.5900198337855761\n",
      "Reddit F1-Score: 0.5889665418318212\n"
     ]
    }
   ],
   "source": [
    "# T/F - Train Reddit, Test Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['Thinking']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['Thinking']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[10] = ['T/F', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b36e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5260236301911587\n",
      "Reddit Precision: 0.5546418366287544\n",
      "Reddit Recall: 0.5260236301911587\n",
      "Reddit F1-Score: 0.5307723844692843\n"
     ]
    }
   ],
   "source": [
    "# J/P - Train Reddit, Test Kaggle\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_reddit['body'])\n",
    "\n",
    "y_train = df_reddit['Judging']\n",
    "\n",
    "X_test = vectorizer.transform(df_kaggle['posts'])\n",
    "\n",
    "y_test = df_kaggle['Judging']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[11] = ['J/P', 'Train Reddit, Test Kaggle', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0661f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.6094906426019018\n",
      "Reddit Precision: 0.66141908480255\n",
      "Reddit Recall: 0.6094906426019018\n",
      "Reddit F1-Score: 0.6304107022469019\n"
     ]
    }
   ],
   "source": [
    "# I/E - Train Kaggle, Test Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['Introvert']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['Introvert']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[12] = ['I/E', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2cbedb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.6843795045727091\n",
      "Reddit Precision: 0.8780164352481126\n",
      "Reddit Recall: 0.6843795045727091\n",
      "Reddit F1-Score: 0.7610736966203913\n"
     ]
    }
   ],
   "source": [
    "# S/N - Train Kaggle, Test Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['Sensing']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['Sensing']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[13] = ['S/N', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "415cbed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5916449639634184\n",
      "Reddit Precision: 0.6548358328825197\n",
      "Reddit Recall: 0.5916449639634184\n",
      "Reddit F1-Score: 0.6062334478899197\n"
     ]
    }
   ],
   "source": [
    "# T/F - Train Kaggle, Test Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['Thinking']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['Thinking']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[14] = ['T/F', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbaaab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Accuracy: 0.5253915571437223\n",
      "Reddit Precision: 0.5202757480914181\n",
      "Reddit Recall: 0.5253915571437223\n",
      "Reddit F1-Score: 0.5225550292741797\n"
     ]
    }
   ],
   "source": [
    "# J/P - Train Kaggle, Test Reddit\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=10,\n",
    "    ngram_range = (1,1)\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_kaggle['posts'])\n",
    "\n",
    "y_train = df_kaggle['Judging']\n",
    "\n",
    "X_test = vectorizer.transform(df_reddit['body'])\n",
    "\n",
    "y_test = df_reddit['Judging']\n",
    "\n",
    "# Encode classes as numerical values for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train_encoded = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# saga solver is stochastic gradient descent model for multiclass classification\n",
    "logistic_regression_model = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "print(f\"Reddit Accuracy: {accuracy}\")\n",
    "\n",
    "precision = precision_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred_lr, average='weighted')\n",
    "print(f\"Reddit F1-Score: {f1}\")\n",
    "\n",
    "df_results_breakdown.loc[15] = ['J/P', 'Train Kaggle, Test Reddit', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "960b57b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbti component</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I/E</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.599028</td>\n",
       "      <td>0.684169</td>\n",
       "      <td>0.599028</td>\n",
       "      <td>0.627363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S/N</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.677009</td>\n",
       "      <td>0.886520</td>\n",
       "      <td>0.677009</td>\n",
       "      <td>0.756436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T/F</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.613812</td>\n",
       "      <td>0.659772</td>\n",
       "      <td>0.613812</td>\n",
       "      <td>0.626723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J/P</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>0.559345</td>\n",
       "      <td>0.577411</td>\n",
       "      <td>0.559345</td>\n",
       "      <td>0.564317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I/E</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.636847</td>\n",
       "      <td>0.660477</td>\n",
       "      <td>0.636847</td>\n",
       "      <td>0.647567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S/N</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.707567</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.707567</td>\n",
       "      <td>0.737517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T/F</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.601329</td>\n",
       "      <td>0.602628</td>\n",
       "      <td>0.601329</td>\n",
       "      <td>0.601793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J/P</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>0.549481</td>\n",
       "      <td>0.551401</td>\n",
       "      <td>0.549481</td>\n",
       "      <td>0.550390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I/E</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.555675</td>\n",
       "      <td>0.667297</td>\n",
       "      <td>0.555675</td>\n",
       "      <td>0.589664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S/N</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.632330</td>\n",
       "      <td>0.777956</td>\n",
       "      <td>0.632330</td>\n",
       "      <td>0.686209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T/F</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.590020</td>\n",
       "      <td>0.588575</td>\n",
       "      <td>0.590020</td>\n",
       "      <td>0.588967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>J/P</td>\n",
       "      <td>Train Reddit, Test Kaggle</td>\n",
       "      <td>0.526024</td>\n",
       "      <td>0.554642</td>\n",
       "      <td>0.526024</td>\n",
       "      <td>0.530772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I/E</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.609491</td>\n",
       "      <td>0.661419</td>\n",
       "      <td>0.609491</td>\n",
       "      <td>0.630411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S/N</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.684380</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.684380</td>\n",
       "      <td>0.761074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T/F</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.591645</td>\n",
       "      <td>0.654836</td>\n",
       "      <td>0.591645</td>\n",
       "      <td>0.606233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>J/P</td>\n",
       "      <td>Train Kaggle, Test Reddit</td>\n",
       "      <td>0.525392</td>\n",
       "      <td>0.520276</td>\n",
       "      <td>0.525392</td>\n",
       "      <td>0.522555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mbti component                    dataset  accuracy  precision    recall  \\\n",
       "0             I/E                     Reddit  0.599028   0.684169  0.599028   \n",
       "1             S/N                     Reddit  0.677009   0.886520  0.677009   \n",
       "2             T/F                     Reddit  0.613812   0.659772  0.613812   \n",
       "3             J/P                     Reddit  0.559345   0.577411  0.559345   \n",
       "4             I/E                     Kaggle  0.636847   0.660477  0.636847   \n",
       "5             S/N                     Kaggle  0.707567   0.777182  0.707567   \n",
       "6             T/F                     Kaggle  0.601329   0.602628  0.601329   \n",
       "7             J/P                     Kaggle  0.549481   0.551401  0.549481   \n",
       "8             I/E  Train Reddit, Test Kaggle  0.555675   0.667297  0.555675   \n",
       "9             S/N  Train Reddit, Test Kaggle  0.632330   0.777956  0.632330   \n",
       "10            T/F  Train Reddit, Test Kaggle  0.590020   0.588575  0.590020   \n",
       "11            J/P  Train Reddit, Test Kaggle  0.526024   0.554642  0.526024   \n",
       "12            I/E  Train Kaggle, Test Reddit  0.609491   0.661419  0.609491   \n",
       "13            S/N  Train Kaggle, Test Reddit  0.684380   0.878016  0.684380   \n",
       "14            T/F  Train Kaggle, Test Reddit  0.591645   0.654836  0.591645   \n",
       "15            J/P  Train Kaggle, Test Reddit  0.525392   0.520276  0.525392   \n",
       "\n",
       "    f1_score  \n",
       "0   0.627363  \n",
       "1   0.756436  \n",
       "2   0.626723  \n",
       "3   0.564317  \n",
       "4   0.647567  \n",
       "5   0.737517  \n",
       "6   0.601793  \n",
       "7   0.550390  \n",
       "8   0.589664  \n",
       "9   0.686209  \n",
       "10  0.588967  \n",
       "11  0.530772  \n",
       "12  0.630411  \n",
       "13  0.761074  \n",
       "14  0.606233  \n",
       "15  0.522555  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_breakdown.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df0b61",
   "metadata": {},
   "source": [
    "This df will be used in analysis in the writeup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
